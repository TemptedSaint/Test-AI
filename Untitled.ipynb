{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9651, 17)\n",
      "Epoch 1/100\n",
      "9651/9651 [==============================] - 1s 135us/step - loss: 0.1610 - acc: 0.8684\n",
      "Epoch 2/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0803 - acc: 0.8684\n",
      "Epoch 3/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0762 - acc: 0.8684\n",
      "Epoch 4/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: 0.0738 - acc: 0.8684\n",
      "Epoch 5/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0718 - acc: 0.8684\n",
      "Epoch 6/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0699 - acc: 0.8684\n",
      "Epoch 7/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0679 - acc: 0.8684\n",
      "Epoch 8/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: 0.0659 - acc: 0.8684\n",
      "Epoch 9/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0637 - acc: 0.8684\n",
      "Epoch 10/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0614 - acc: 0.8684\n",
      "Epoch 11/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: 0.0589 - acc: 0.8684\n",
      "Epoch 12/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: 0.0566 - acc: 0.8684\n",
      "Epoch 13/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0538 - acc: 0.8684\n",
      "Epoch 14/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0510 - acc: 0.8684\n",
      "Epoch 15/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: 0.0483 - acc: 0.8684\n",
      "Epoch 16/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0453 - acc: 0.8684\n",
      "Epoch 17/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0423 - acc: 0.8684\n",
      "Epoch 18/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0396 - acc: 0.8684\n",
      "Epoch 19/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: 0.0367 - acc: 0.8684\n",
      "Epoch 20/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0335 - acc: 0.8684\n",
      "Epoch 21/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0309 - acc: 0.8684\n",
      "Epoch 22/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0286 - acc: 0.8684\n",
      "Epoch 23/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: 0.0257 - acc: 0.8715\n",
      "Epoch 24/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0227 - acc: 0.8719\n",
      "Epoch 25/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0199 - acc: 0.8719\n",
      "Epoch 26/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0171 - acc: 0.8719\n",
      "Epoch 27/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: 0.0146 - acc: 0.8727\n",
      "Epoch 28/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0122 - acc: 0.8735\n",
      "Epoch 29/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0095 - acc: 0.8735\n",
      "Epoch 30/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: 0.0076 - acc: 0.8735\n",
      "Epoch 31/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: 0.0058 - acc: 0.8735\n",
      "Epoch 32/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0034 - acc: 0.8759\n",
      "Epoch 33/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: 0.0022 - acc: 0.8863\n",
      "Epoch 34/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: 2.3178e-04 - acc: 0.8885\n",
      "Epoch 35/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0013 - acc: 0.8885\n",
      "Epoch 36/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0025 - acc: 0.8885\n",
      "Epoch 37/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0037 - acc: 0.8885\n",
      "Epoch 38/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0048 - acc: 0.8885\n",
      "Epoch 39/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0061 - acc: 0.8885\n",
      "Epoch 40/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0067 - acc: 0.8885\n",
      "Epoch 41/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0080 - acc: 0.8885\n",
      "Epoch 42/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0088 - acc: 0.8885\n",
      "Epoch 43/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0099 - acc: 0.8885\n",
      "Epoch 44/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0102 - acc: 0.8885\n",
      "Epoch 45/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0112 - acc: 0.8885\n",
      "Epoch 46/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0117 - acc: 0.8885\n",
      "Epoch 47/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0126 - acc: 0.8885\n",
      "Epoch 48/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0131 - acc: 0.8885\n",
      "Epoch 49/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0135 - acc: 0.8885\n",
      "Epoch 50/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0142 - acc: 0.8885\n",
      "Epoch 51/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0147 - acc: 0.8885\n",
      "Epoch 52/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0152 - acc: 0.8885\n",
      "Epoch 53/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0153 - acc: 0.8885\n",
      "Epoch 54/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0161 - acc: 0.8885\n",
      "Epoch 55/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0166 - acc: 0.8885\n",
      "Epoch 56/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0166 - acc: 0.8885\n",
      "Epoch 57/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0174 - acc: 0.8885\n",
      "Epoch 58/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0173 - acc: 0.8885\n",
      "Epoch 59/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0180 - acc: 0.8885\n",
      "Epoch 60/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0185 - acc: 0.8885\n",
      "Epoch 61/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0188 - acc: 0.8885\n",
      "Epoch 62/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0191 - acc: 0.8885\n",
      "Epoch 63/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0192 - acc: 0.8885\n",
      "Epoch 64/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0197 - acc: 0.8885\n",
      "Epoch 65/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: -0.0199 - acc: 0.8885\n",
      "Epoch 66/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0204 - acc: 0.8885\n",
      "Epoch 67/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0205 - acc: 0.8885\n",
      "Epoch 68/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0210 - acc: 0.8885\n",
      "Epoch 69/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0213 - acc: 0.8885\n",
      "Epoch 70/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0214 - acc: 0.8885\n",
      "Epoch 71/100\n",
      "9651/9651 [==============================] - 1s 91us/step - loss: -0.0217 - acc: 0.8885\n",
      "Epoch 72/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0214 - acc: 0.8885\n",
      "Epoch 73/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0221 - acc: 0.8885\n",
      "Epoch 74/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0224 - acc: 0.8885\n",
      "Epoch 75/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0227 - acc: 0.8885\n",
      "Epoch 76/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0228 - acc: 0.8885\n",
      "Epoch 77/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0227 - acc: 0.8885\n",
      "Epoch 78/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0234 - acc: 0.8885\n",
      "Epoch 79/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0236 - acc: 0.8885\n",
      "Epoch 80/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0239 - acc: 0.8885\n",
      "Epoch 81/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0240 - acc: 0.8885\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0243 - acc: 0.8885\n",
      "Epoch 83/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0246 - acc: 0.8885\n",
      "Epoch 84/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0248 - acc: 0.8885\n",
      "Epoch 85/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0251 - acc: 0.8885\n",
      "Epoch 86/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0250 - acc: 0.8885\n",
      "Epoch 87/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0254 - acc: 0.8885\n",
      "Epoch 88/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0255 - acc: 0.8885\n",
      "Epoch 89/100\n",
      "9651/9651 [==============================] - 1s 92us/step - loss: -0.0258 - acc: 0.8885\n",
      "Epoch 90/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0261 - acc: 0.8885\n",
      "Epoch 91/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0263 - acc: 0.8885\n",
      "Epoch 92/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0266 - acc: 0.8885\n",
      "Epoch 93/100\n",
      "9651/9651 [==============================] - 1s 89us/step - loss: -0.0268 - acc: 0.8885\n",
      "Epoch 94/100\n",
      "9651/9651 [==============================] - 1s 88us/step - loss: -0.0269 - acc: 0.8885\n",
      "Epoch 95/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0273 - acc: 0.8885\n",
      "Epoch 96/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0275 - acc: 0.8885\n",
      "Epoch 97/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0276 - acc: 0.8885\n",
      "Epoch 98/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0279 - acc: 0.8885\n",
      "Epoch 99/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0282 - acc: 0.8885\n",
      "Epoch 100/100\n",
      "9651/9651 [==============================] - 1s 90us/step - loss: -0.0283 - acc: 0.8885\n",
      "9651/9651 [==============================] - 0s 21us/step\n",
      "\n",
      "acc: 88.85%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "#disclaimer this is 0.5.6c \n",
    "#the c means that it is slim lined to prevent ram overflow with only 25 as batch size compared to 100\n",
    "#this does not have the plot flows or neural mapping if you would like that I can give you b\n",
    "#by givining you b it will cost 24 gb of ram\n",
    "\n",
    "#for the sample set you must remove the header row, it will break the reading and set values turning all columns to strings instead of just two\n",
    "sampleset = np.loadtxt(\"test.csv\", dtype=float, delimiter=\",\")\n",
    "# due to string values messing with the single delimiter in a float array I split the input into two seperate arrays\n",
    "samplestringset = np.loadtxt(\"teststring.csv\", dtype=str, delimiter=\",\")\n",
    "#initializes train set as empty to be filled by logic table\n",
    "trainset = np.empty((0))\n",
    "\n",
    "#removing of the 5 and converting 2 to 1\n",
    "#changing 1 to 0, 3 to 1 and 4 to 2\n",
    "#changing names to comparison values\n",
    "\n",
    "rowcount,colcount = sampleset.shape\n",
    "rawcount,x = sampleset.shape\n",
    "rowcount -=1\n",
    "colcount -=1\n",
    "while (rowcount > -1):\n",
    "    parseset = sampleset[rowcount,:]\n",
    "    if (parseset.item((colcount)) < 5):\n",
    "        # entire ladder to redistribute the recruiting values\n",
    "        if (parseset.item((colcount)) == 1):\n",
    "            parseset[colcount] = 0\n",
    "        elif (parseset.item((colcount)) == 2):\n",
    "            parseset[colcount] = 0\n",
    "        elif (parseset.item((colcount)) == 3):\n",
    "            parseset[colcount] = 1\n",
    "        elif (parseset.item((colcount)) == 4):\n",
    "            parseset[colcount] = 2\n",
    "        handle = samplestringset[rowcount,0]\n",
    "        moniker = samplestringset[rowcount,1]\n",
    "        hanlen = len(handle)\n",
    "        monlen = len(moniker)\n",
    "        tempset = np.empty((0))\n",
    "        # charecter count\n",
    "        charcnt = int(0)\n",
    "        # charecter comparison count\n",
    "        compcnt = int(0)\n",
    "        # total comparison float\n",
    "        strcomp = float(0)\n",
    "        if hanlen >= monlen:\n",
    "            while (charcnt < monlen):\n",
    "                if (handle[charcnt] == moniker[charcnt]):\n",
    "                    compcnt += 1\n",
    "                charcnt += 1\n",
    "            strcomp = compcnt / charcnt\n",
    "        else:\n",
    "            while (charcnt < hanlen):\n",
    "                if handle[charcnt] == moniker[charcnt]:\n",
    "                    compcnt += 1\n",
    "                charcnt += 1\n",
    "            strcomp = compcnt/charcnt\n",
    "        a = np.empty((0))\n",
    "        a = np.append(a, strcomp)\n",
    "        #this will create the entire new array with the strings accounted for in comparison with recruiting value at the end\n",
    "        tempset = np.empty((0))\n",
    "        tempset = np.append(tempset, values=parseset[:colcount])\n",
    "        tempset = np.append(tempset, values=[strcomp])\n",
    "        tempset = np.append(tempset, values=parseset[colcount])\n",
    "        if ((rowcount+1) == rawcount):\n",
    "            trainset = tempset\n",
    "        else:\n",
    "            trainset = np.vstack([trainset, tempset])\n",
    "    rowcount -= 1\n",
    "    \n",
    "print(trainset.shape)\n",
    "# converting the data set so that it can be used for training\n",
    "\n",
    "traindata,checkdata = trainset[:,:16],trainset[:,16]\n",
    "\n",
    "# build nueral net\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=16, activation='relu'))\n",
    "model.add(Dense(7, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='hard_sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# variable loss with optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "# assigning the data set\n",
    "model.fit(traindata, checkdata, epochs=100, batch_size=10)\n",
    "\n",
    "# evaluate the model still working on the version of the check that I am using, it is very inefficient\n",
    "scores = model.evaluate(traindata, checkdata)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "#saves the model\n",
    "model.save('adi.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
