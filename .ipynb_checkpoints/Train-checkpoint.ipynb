{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions here, remember to add to requirements.txt if a package needs to be install via pip\n",
    "import numpy as np\n",
    "import datetime\n",
    "import MySQLdb\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Production MySql settings\n",
    "MYSQL_CREDS = {\n",
    "    \"host\": \"10.24.14.51\",\n",
    "    \"port\": 3306,\n",
    "    \"user\": \"RecruitSuggester\",\n",
    "    \"passwd\": \"HPwtdJlaLq2whEH9\",\n",
    "    \"db\": \"DeepLearning\",\n",
    "}\n",
    "\n",
    "# Uncommit the 2 lines below for remote testing.\n",
    "MYSQL_CREDS[\"host\"] = \"198.154.109.168\" # Test IP - uncomment if testing from home\n",
    "MYSQL_CREDS[\"port\"] = 33306 # Test Port - uncomment if testing from home\n",
    "\n",
    "MASTER_DATA_QUERY = \"\"\"\n",
    "SELECT\n",
    "    Handle, Moniker, ForumID, SpectrumID, Country, State,\n",
    "    Fluency0, Fluency1, Fluency2, Fluency3, Fluency4, Enlisted,\n",
    "    ForumLastActive, ChatLastActive, CustomAvatar, InviteSent, Outcome\n",
    "FROM\n",
    "    MasterData\n",
    "\"\"\"\n",
    "\n",
    "COUNTRY_QUERY = \"SELECT CountryID, CountryName from Countries\"\n",
    "LANGUAGE_QUERY = \"SELECT LanguageID, LanguageName from Languages\"\n",
    "\n",
    "\n",
    "# # Ho0ber log function, added time stamps to print\n",
    "def log(message):\n",
    "    print(\"{}::  {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), message))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "class DeepLearning(object):\n",
    "    def __init__(self):\n",
    "        self.mysql_conn = MySQLdb.connect(**MYSQL_CREDS)\n",
    "        self.languages = {}\n",
    "        self.countries = {}\n",
    "        self.pull_languages_and_countries()\n",
    "\n",
    "    def pull_languages_and_countries(self):\n",
    "        \"\"\"\n",
    "        Cache Languages and Countries tables into local dicts to save MySQL hits for\n",
    "        known values. Any new values will need to be added to these when discovered.\n",
    "        \"\"\"\n",
    "        log(\"Caching language and country data locally...\")\n",
    "        cursor = self.mysql_conn.cursor()\n",
    "\n",
    "        cursor.execute(COUNTRY_QUERY)\n",
    "        for cid,country in cursor.fetchall():\n",
    "            self.countries[country] = cid\n",
    "\n",
    "        cursor.execute(LANGUAGE_QUERY)\n",
    "        for lid,language in cursor.fetchall():\n",
    "            self.languages[language] = lid\n",
    "\n",
    "    def get_or_create_country(self, country):\n",
    "        # TODO - make this actually:\n",
    "        # - Add new countries to MySQL\n",
    "        # - Get the ID from the newly created country row\n",
    "        # - Add row to local cache dict\n",
    "        # - Return the new ID\n",
    "        return self.countries.get(country, 0) if country else None\n",
    "\n",
    "    def get_or_create_language(self, language):\n",
    "        # TODO - make this actually:\n",
    "        # - Add new languages to MySQL\n",
    "        # - Get the ID from the newly created language row\n",
    "        # - Add row to local cache dict\n",
    "        # - Return the new ID\n",
    "        return self.languages.get(language, 0) if language else None\n",
    "\n",
    "    def clean(self, row):\n",
    "        \"\"\"\n",
    "        Strip off the first two columns and numericize country and fluency fields.\n",
    "        \"\"\"\n",
    "        row = list(row) # Make the row mutable by changing to a list\n",
    "\n",
    "        # Change country into CountryID\n",
    "        row[4] = self.get_or_create_country(row[4])\n",
    "\n",
    "        # Change all fluency fields into LanguageIDs\n",
    "        for col in range(6,11):\n",
    "            row[col] = self.get_or_create_language(row[col])\n",
    "\n",
    "        # Return the resulting row, but strip off handle and moniker\n",
    "        return [col if col != '' else None for col in row[2:]]\n",
    "\n",
    "    def pull_data(self):\n",
    "        \"\"\"\n",
    "        This function pulls MasterData from MySQL and produces two numpy 2d arrays:\n",
    "        1) sampleset - A numericized version of most columns\n",
    "        2) samplestringset - Only handle and moniker as strings\n",
    "\n",
    "        This can probably be changed to just one 2d array, but this was easier to\n",
    "        interface with the train code as written.\n",
    "        \"\"\"\n",
    "        cursor = self.mysql_conn.cursor()\n",
    "        numrows = cursor.execute(MASTER_DATA_QUERY)\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Pull out just handle and moniker for samplestringset\n",
    "        names = [[r[0], r[1]] for r in results]\n",
    "\n",
    "        # Strip off the first two columns and numericize country and fluency fields\n",
    "        numbers = [self.clean(row) for row in results]\n",
    "\n",
    "        # I went for np.array directly rather than fromiter because fromiter was finicky\n",
    "        # We might need to change that, but I'm uncertain\n",
    "        sampleset = np.array(numbers)\n",
    "        samplestringset = np.array(names)\n",
    "\n",
    "        return sampleset, samplestringset\n",
    "\n",
    "    def train(self, sampleset, samplestringset):\n",
    "        \"\"\"\n",
    "        This is TemptedSaint's code, nearly verbatim. I can't comment on it\n",
    "        other than to note that I changed a bunch of 16s to 15s after we cut\n",
    "        out our internal identifier. I wasn't certain if any other numbers needed\n",
    "        to be shifted as a result.\n",
    "\n",
    "        I know I borked something, as the accuracy is 0% when I run this.\n",
    "        \"\"\"\n",
    "        sampleset[sampleset == None] = 0\n",
    "        trainset = np.empty((0))\n",
    "\n",
    "        #removing of the 5 and converting 2 to 1\n",
    "        #changing 1 to 0, 3 to 1 and 4 to 2\n",
    "        #changing names to comparison values\n",
    "\n",
    "        rowcount,colcount = sampleset.shape\n",
    "        rawcount,x = sampleset.shape\n",
    "        rowcount -=1\n",
    "        colcount -=1\n",
    "        while (rowcount > -1):\n",
    "            handle = samplestringset[rowcount,0]\n",
    "            moniker = samplestringset[rowcount,1]\n",
    "            hanlen = len(handle)\n",
    "            monlen = len(moniker)\n",
    "            tempset = np.empty((0))\n",
    "            # charecter count\n",
    "            charcnt = int(0)\n",
    "            # charecter comparison count\n",
    "            compcnt = int(0)\n",
    "            # total comparison float\n",
    "            strcomp = float(0)\n",
    "            if hanlen >= monlen:\n",
    "                while (charcnt < monlen):\n",
    "                    if (handle[charcnt] == moniker[charcnt]):\n",
    "                        compcnt += 1\n",
    "                    charcnt += 1\n",
    "                strcomp = compcnt / charcnt\n",
    "            else:\n",
    "                while (charcnt < hanlen):\n",
    "                    if handle[charcnt] == moniker[charcnt]:\n",
    "                        compcnt += 1\n",
    "                    charcnt += 1\n",
    "                strcomp = compcnt/charcnt\n",
    "            a = np.empty((0))\n",
    "            a = np.append(a, strcomp)\n",
    "            #this will create the entire new array with the strings accounted for in comparison with recruiting value at the end\n",
    "            tempset = np.empty((0))\n",
    "            tempset = np.append(tempset, values=sampleset[rowcount, :colcount])\n",
    "            tempset = np.append(tempset, values=[strcomp])\n",
    "            tempset = np.append(tempset, values=sampleset[rowcount, colcount])\n",
    "            if ((rowcount+1) == rawcount):\n",
    "                trainset = tempset\n",
    "            else:\n",
    "                trainset = np.vstack([trainset, tempset])\n",
    "            rowcount -= 1\n",
    "\n",
    "        log(trainset.shape)\n",
    "        # converting the data set so that it can be used for training\n",
    "        colcount += 1\n",
    "        traindata,checkdata = trainset[:,:colcount],trainset[:,colcount]\n",
    "        # build nueral net\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(colcount, input_dim=colcount, activation='relu'))\n",
    "        model.add(Dense(7, activation='sigmoid'))\n",
    "        model.add(Dense(5, activation='hard_sigmoid'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # variable loss with optimizer\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
    "        # assigning the data set\n",
    "        model.fit(traindata, checkdata, epochs=100, batch_size=10)\n",
    "\n",
    "        # evaluate the model still working on the version of the check that I am using, it is very inefficient\n",
    "        scores = model.evaluate(traindata, checkdata)\n",
    "        log(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "        #saves the model\n",
    "        model.save('adi.hd5')\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Main entry-point for the class. pull_data into numpy arrays, then pass them off to train\n",
    "        \"\"\"\n",
    "        log(\"Pulling MasterData from MySQL...\")\n",
    "        sampleset, samplestringset = self.pull_data()\n",
    "\n",
    "        log(\"Training model...\")\n",
    "        self.train(sampleset, samplestringset)\n",
    "\n",
    "        log(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    DeepLearning().run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
